[TOC]



# 1、前言

tRPC-Go 的超时控制只发生在客户端在调用服务时，控制调用等待的时间。如果超过设定时间，客户端调用立刻返回超时失败。

超时控制主要有下面三个影响因素：

- `链路超时`：上游调用方通过协议字段把自己允许的超时时间传给当前服务，意思是说我只给你这么多的超时时间，请`在该超时时间内务必给我返回数据`，超过这个时间返回都是没有意义的，如下图的 A 调用 B 的`总链路超时时间`。
- `消息超时`：当前服务配置的从`收到请求消息到返回响应数据`的最长消息处理时间，这是当前服务控制自身不浪费资源的手段，如下图的 B 内部的`当前请求整体超时时间`。
- `调用超时`：当前服务调用下游服务设置的每一个 rpc 请求的超时时间，如下图的 B 调用 C 的`单个超时时间`。通常一次请求会连续调用多次 rpc，如下图 B 调完 C，继续串行调用 D 和 E，这个调用超时控制的是每个 rpc 的独立超时时间。

发起 rpc 调用请求时，需要计算此次 rpc 调用的超时时间。真正生效的超时时间是通过以上三个因素实时计算的最小值，计算过程如下：

- 首先计算得到`链路超时和消息超时的最小值`，比如：链路超时 2s，消息超时 1s，则当前消息允许的最长处理时间为 1s。
- 发起 rpc 调用时，再次计算`当前消息最长处理时间和单个超时时间的最小值`，比如：下图的 B->C 设置的单个超时时间为 5s，则实际上 B 调用 C 的真实超时仍然是 1s，其实只要超时时间大于当前最长处理时间都是无效的，都会取最小值。再比如 B->C 单个超时时间为 500ms，这种情况 B 调用 C 的真实超时即为 500ms，此时 500ms 这个值也会通过协议字段传给 C，在服务端 C 的视角来看就是他的链路超时时间。链路超时时间会在整个 rpc 调用链上一直传递下去，并逐渐减少，直至为 0，这样也就永远不会出现死循环调用的问题。
- 因为每一次 rpc 调用都会实际消耗一部分时间，所以`当前消息最长处理时间需要实时计算剩余时间`，比如上面 B 调用 C 真实耗时 200ms，此时最长处理时间就只剩下 800ms 了。此时发起第二次 rpc 调用时，则需要计算此时剩余的消息超时时间和单个调用时间的最小值。如下图的 B->D 设置的单个超时时间为 1s，则实际生效的超时时间仍然为 800ms。

# 全链路超时控制模型原理图
tRPC-Go 全链路超时控制模型原理图
![ 'timeout_control.png'](/.resources/user_guide/timeout_control/timeout_control.png)

# 超时控制实现
tRPC-Go 的超时控制都是`基于context能力`实现的。
context 是请求上下文的意思，是所有 rpc 接口的第一个参数，可以设置超时，取消。所以要实现 tRPC-Go 的超时控制，所有的 rpc 调用都必须一路携带请求入口的 ctx。`必须注意：超时只有通过ctx才能控制`。
context 只能控制每次调用的超时时间，不能控制协程的结束，如果业务代码里面没有使用 ctx，而是使用了纯内存耗时计算（如 time.Sleep，select，以及未带 ctx 调用等）就控制不了超时了，协程也就会永远卡住无法退出。
context 在 server 收到请求时，会根据协议里面的 timeout 字段和框架配置的 timeout 字段，设置好当前请求的最长处理时间，然后交给用户使用，并在处理函数结束时会立马 cancel 掉当前 context。所以当你自己通过 go 启动协程处理异步逻辑时，一定不能再使用请求入口的 context，必须使用新的 context，如`trpc.BackgroundContext()`。

# 超时配置示例
tRPC-Go 的超时控制全部通过配置文件指定即可。
注意：以下设置的均是当前服务自身的超时配置，不是上游对自己的超时配置。

## 链路超时
超时时间默认会从最源头服务一直通过协议字段透传下去，用户可以自己配置开关开启或关闭。
链路超时是由上游 client 调用方决定的，如果 client 没有设置，那就没有链路超时，不需要配置关闭。
trpc-client 默认都会将当前的 rpc 实际超时时间设置到链路超时里面，其他 client 一般不会设置。
```yaml
server:
  service:
    - name: trpc.app.server.service
      disable_request_timeout: true  # 默认 false，默认超时时间会继承上游的设置时间，配置 true 则禁用，表示忽略上游服务调用我时协议传递过来的超时时间
```
在一些事务场景下，需要全部成功或者全部失败时，可配置此值。

## 消息超时
每个服务启动时都可配置该服务所有请求的最长处理超时时间，该时间只会在调用下游服务时生效。
如果服务端通过执行纯内存耗时操作（如 time.Sleep，select，以及未带 ctx 调用等）导致处理请求的时间超过了消息超时时间，处理协程不会立马结束。
`必须注意：超时只有通过ctx才能控制。`
```yaml
server:
  service:
    - name: trpc.app.server.service
      timeout: 1000  # 单位 ms，每个接收到的请求最多允许 1000ms 的执行时间，所以要注意权衡当前请求内的所有串行 rpc 调用的超时时间分配，默认为 0，不设置超时
```

## 调用超时
每个 rpc 后端调用都可以配置当次调用请求的最大超时时间，如果代码里面有设置`WithTimeout Option`，则`调用超时以代码为准，该配置不生效`，代码不够灵活，建议不要在代码里面设置 WithTimeout Option。
`必须注意：超时只有通过ctx才能控制。`
```yaml
client:
  service:
    - name: trpc.app.server.service  # 后端服务协议文件的 service name，格式为：pbpackagename.pbservicename
      timeout: 500  # 单位 ms，每个发起的请求最多允许 500ms 的超时时间，默认为 0，不设置超时，即无限等待
```
每次 rpc 请求会取`链路超时`、`消息超时`、`调用超时`的最小值来调用后端，当前消息的最长处理超时时间会实时计算剩余时间。